{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise de Confiabilidade - Alpha de Cronbach\n",
        "\n",
        "Este notebook calcula o **Alpha de Cronbach** para avaliar a consistência interna de diferentes blocos de questões do questionário.\n",
        "\n",
        "## Blocos Analisados:\n",
        "\n",
        "1. **Bloco 1 - Conhecimento antes do curso** (7 questões)\n",
        "2. **Bloco 2 - Conhecimento depois do curso** (7 questões)\n",
        "3. **Bloco 3 - Motivação** (5 questões)\n",
        "4. **Bloco 4 - Percepção de contribuição** (1 questão - análise especial)\n",
        "\n",
        "## Métricas Calculadas:\n",
        "\n",
        "- Alpha de Cronbach (α)\n",
        "- Correlações item-total\n",
        "- Alpha se item deletado\n",
        "- Estatísticas descritivas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuração de estilo para artigos acadêmicos\n",
        "plt.rcParams.update({\n",
        "    'font.size': 11,\n",
        "    'font.family': 'serif',\n",
        "    'font.serif': ['Times New Roman', 'DejaVu Serif', 'Computer Modern Roman'],\n",
        "    'axes.labelsize': 12,\n",
        "    'axes.titlesize': 13,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10,\n",
        "    'legend.fontsize': 10,\n",
        "    'figure.titlesize': 14,\n",
        "    'axes.linewidth': 1.2,\n",
        "    'grid.linewidth': 0.8,\n",
        "    'grid.alpha': 0.3,\n",
        "    'lines.linewidth': 2,\n",
        "    'patch.linewidth': 1.2,\n",
        "    'xtick.major.width': 1.2,\n",
        "    'ytick.major.width': 1.2,\n",
        "    'figure.dpi': 300,\n",
        "    'savefig.dpi': 300,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'savefig.pad_inches': 0.1\n",
        "})\n",
        "\n",
        "# Paleta de cores para impressão (acessível e profissional)\n",
        "colors_academic = {\n",
        "    'primary': '#2C3E50',      # Azul escuro\n",
        "    'secondary': '#34495E',     # Cinza azulado\n",
        "    'accent1': '#3498DB',      # Azul\n",
        "    'accent2': '#E74C3C',      # Vermelho\n",
        "    'accent3': '#27AE60',      # Verde\n",
        "    'accent4': '#F39C12',      # Laranja\n",
        "    'light': '#ECF0F1',        # Cinza claro\n",
        "    'dark': '#1A1A1A'          # Preto\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para calcular Alpha de Cronbach\n",
        "def cronbach_alpha(df):\n",
        "    \"\"\"\n",
        "    Calcula o Alpha de Cronbach para um conjunto de itens.\n",
        "    \n",
        "    Parâmetros:\n",
        "    df: DataFrame com os itens nas colunas\n",
        "    \n",
        "    Retorna:\n",
        "    alpha: Valor do Alpha de Cronbach\n",
        "    \"\"\"\n",
        "    df_clean = df.dropna()\n",
        "    if df_clean.shape[0] < 2:\n",
        "        return np.nan\n",
        "    \n",
        "    # Número de itens\n",
        "    k = df_clean.shape[1]\n",
        "    \n",
        "    if k < 2:\n",
        "        return np.nan\n",
        "    \n",
        "    # Variância de cada item\n",
        "    item_var = df_clean.var(axis=0, ddof=1)\n",
        "    \n",
        "    # Variância total (soma dos itens)\n",
        "    total_var = df_clean.sum(axis=1).var(ddof=1)\n",
        "    \n",
        "    # Calcular alpha\n",
        "    alpha = (k / (k - 1)) * (1 - item_var.sum() / total_var)\n",
        "    \n",
        "    return alpha\n",
        "\n",
        "# Função para calcular correlações item-total\n",
        "def item_total_correlation(df):\n",
        "    \"\"\"\n",
        "    Calcula a correlação de cada item com o total (sem o próprio item).\n",
        "    \n",
        "    Parâmetros:\n",
        "    df: DataFrame com os itens nas colunas\n",
        "    \n",
        "    Retorna:\n",
        "    correlations: Series com correlações item-total\n",
        "    \"\"\"\n",
        "    df_clean = df.dropna()\n",
        "    correlations = {}\n",
        "    \n",
        "    for col in df_clean.columns:\n",
        "        # Total sem o item atual\n",
        "        total_sem_item = df_clean.drop(columns=[col]).sum(axis=1)\n",
        "        # Correlação item-total\n",
        "        corr, _ = pearsonr(df_clean[col], total_sem_item)\n",
        "        correlations[col] = corr\n",
        "    \n",
        "    return pd.Series(correlations)\n",
        "\n",
        "# Função para calcular alpha se item deletado\n",
        "def alpha_if_deleted(df):\n",
        "    \"\"\"\n",
        "    Calcula o alpha se cada item for removido.\n",
        "    \n",
        "    Parâmetros:\n",
        "    df: DataFrame com os itens nas colunas\n",
        "    \n",
        "    Retorna:\n",
        "    alphas: Series com alpha se item deletado\n",
        "    \"\"\"\n",
        "    df_clean = df.dropna()\n",
        "    alphas = {}\n",
        "    \n",
        "    for col in df_clean.columns:\n",
        "        df_sem_item = df_clean.drop(columns=[col])\n",
        "        if df_sem_item.shape[1] >= 2:\n",
        "            alphas[col] = cronbach_alpha(df_sem_item)\n",
        "        else:\n",
        "            alphas[col] = np.nan\n",
        "    \n",
        "    return pd.Series(alphas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar os dados\n",
        "df = pd.read_csv(\"../csv/feedback-v2.csv\")\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(f\"Shape do dataset: {df.shape}\")\n",
        "print(f\"Total de colunas: {len(df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bloco 1: Conhecimento Antes do Curso\n",
        "\n",
        "Preparar as 7 questões sobre conhecimento antes da disciplina.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapear questões de conhecimento antes\n",
        "# Escala: 0=Nenhum, 1=Baixo, 2=Médio, 3=Alto\n",
        "conhecimento_scale = {\n",
        "    \"Nenhum. Não conhecia.\": 0,\n",
        "    \"Baixo. Adquiri conhecimentos básicos em aulas ou livros.\": 1,\n",
        "    \"Médio. Já havia utilizado em projetos de pesquisa.\": 2,\n",
        "    \"Alto. Já havia utilizado em cinco ou mais projetos.\": 3\n",
        "}\n",
        "\n",
        "# Mapear todas as variações possíveis\n",
        "conhecimento_scale_extended = {\n",
        "    \"Nenhum. Não conhecia.\": 0,\n",
        "    \"Nenhum\": 0,\n",
        "    \"Baixo. Adquiri conhecimentos básicos em aulas ou livros.\": 1,\n",
        "    \"Baixo\": 1,\n",
        "    \"Médio. Já havia utilizado em projetos de pesquisa.\": 2,\n",
        "    \"Médio\": 2,\n",
        "    \"Alto. Já havia utilizado em cinco ou mais projetos.\": 3,\n",
        "    \"Alto\": 3\n",
        "}\n",
        "\n",
        "# Colunas de conhecimento antes\n",
        "bloco1_cols = [\n",
        "    'Qual seu nível de conhecimento sobre tipos de estudos experimentais (primários, secundários e terciários) antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre experimento controlado antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre estudo de caso antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre Survey antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre análise estatística de experimentos antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre análise qualitativa antes da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre revisão sistemática da literatura (RSL) antes da disciplina?'\n",
        "]\n",
        "\n",
        "# Criar DataFrame para Bloco 1\n",
        "bloco1 = pd.DataFrame()\n",
        "for col in bloco1_cols:\n",
        "    if col in df.columns:\n",
        "        # Tentar mapear com diferentes variações\n",
        "        bloco1[col] = df[col].map(conhecimento_scale_extended)\n",
        "        # Se não mapeou, tentar valores numéricos diretos\n",
        "        if bloco1[col].isna().all():\n",
        "            bloco1[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Renomear colunas para nomes mais curtos\n",
        "bloco1.columns = [\n",
        "    'Estudos experimentais (antes)',\n",
        "    'Experimento controlado (antes)',\n",
        "    'Estudo de caso (antes)',\n",
        "    'Survey (antes)',\n",
        "    'Análise estatística (antes)',\n",
        "    'Análise qualitativa (antes)',\n",
        "    'RSL (antes)'\n",
        "]\n",
        "\n",
        "print(\"Bloco 1 - Conhecimento Antes:\")\n",
        "print(f\"Shape: {bloco1.shape}\")\n",
        "print(f\"\\nValores únicos por item:\")\n",
        "for col in bloco1.columns:\n",
        "    print(f\"  {col}: {sorted(bloco1[col].dropna().unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bloco 2: Conhecimento Depois do Curso\n",
        "\n",
        "Preparar as 7 questões sobre conhecimento depois da disciplina.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colunas de conhecimento depois\n",
        "bloco2_cols = [\n",
        "    'Qual seu nível de conhecimento sobre tipos de estudos experimentais (primários, secundários e terciários) após da disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre experimento controlado após a disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre estudo de caso após a disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre Survey após a disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre análise estatística de experimentos após a disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre análise qualitativa após a disciplina?',\n",
        "    'Qual seu nível de conhecimento sobre revisão sistemática da literatura (RSL) após a disciplina?'\n",
        "]\n",
        "\n",
        "# Criar DataFrame para Bloco 2\n",
        "bloco2 = pd.DataFrame()\n",
        "for col in bloco2_cols:\n",
        "    if col in df.columns:\n",
        "        bloco2[col] = df[col].map(conhecimento_scale_extended)\n",
        "        if bloco2[col].isna().all():\n",
        "            bloco2[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Renomear colunas\n",
        "bloco2.columns = [\n",
        "    'Estudos experimentais (depois)',\n",
        "    'Experimento controlado (depois)',\n",
        "    'Estudo de caso (depois)',\n",
        "    'Survey (depois)',\n",
        "    'Análise estatística (depois)',\n",
        "    'Análise qualitativa (depois)',\n",
        "    'RSL (depois)'\n",
        "]\n",
        "\n",
        "print(\"Bloco 2 - Conhecimento Depois:\")\n",
        "print(f\"Shape: {bloco2.shape}\")\n",
        "print(f\"\\nValores únicos por item:\")\n",
        "for col in bloco2.columns:\n",
        "    print(f\"  {col}: {sorted(bloco2[col].dropna().unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bloco 3: Motivação\n",
        "\n",
        "Preparar as 5 questões de motivação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escala de motivação: 1=Desmotivado, 2=Neutro, 3=Motivado, 4=Muito motivado\n",
        "motiv_scale = {\n",
        "    \"Desmotivado(a)\": 1,\n",
        "    \"Neutro(a)\": 2,\n",
        "    \"Motivado(a)\": 3,\n",
        "    \"Muito motivado(a)\": 4\n",
        "}\n",
        "\n",
        "# Colunas de motivação\n",
        "bloco3_cols = [\n",
        "    \"Estudo de caso\",\n",
        "    \"Survey\", \n",
        "    \"Revisão Sistemática da Literatura (RSL)\", \n",
        "    \"Análise Estatística de Experimentos\", \n",
        "    \"Análise Qualitativa\"\n",
        "]\n",
        "\n",
        "# Criar DataFrame para Bloco 3\n",
        "bloco3 = pd.DataFrame()\n",
        "for col in bloco3_cols:\n",
        "    if col in df.columns:\n",
        "        bloco3[col] = df[col].map(motiv_scale)\n",
        "        if bloco3[col].isna().all():\n",
        "            bloco3[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "print(\"Bloco 3 - Motivação:\")\n",
        "print(f\"Shape: {bloco3.shape}\")\n",
        "print(f\"\\nValores únicos por item:\")\n",
        "for col in bloco3.columns:\n",
        "    print(f\"  {col}: {sorted(bloco3[col].dropna().unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escala de percepção: 1=Discordo totalmente, 2=Discordo, 3=Neutro, 4=Concordo, 5=Concordo totalmente\n",
        "contrib_scale = {\n",
        "    \"Discordo totalmente\": 1,\n",
        "    \"Discordo\": 2,\n",
        "    \"Neutro\": 3,\n",
        "    \"Concordo\": 4,\n",
        "    \"Concordo totalmente\": 5\n",
        "}\n",
        "\n",
        "# Coluna de percepção de contribuição\n",
        "bloco4_col = 'Você acredita que a disciplina vai contribuir para sua formação?'\n",
        "\n",
        "# Criar DataFrame para Bloco 4\n",
        "bloco4 = pd.DataFrame()\n",
        "if bloco4_col in df.columns:\n",
        "    bloco4[bloco4_col] = df[bloco4_col].map(contrib_scale)\n",
        "    if bloco4[bloco4_col].isna().all():\n",
        "        bloco4[bloco4_col] = pd.to_numeric(df[bloco4_col], errors='coerce')\n",
        "    bloco4.columns = ['Percepção de Contribuição']\n",
        "\n",
        "print(\"Bloco 4 - Percepção de Contribuição:\")\n",
        "print(f\"Shape: {bloco4.shape}\")\n",
        "print(f\"\\nValores únicos:\")\n",
        "print(f\"  {bloco4.columns[0]}: {sorted(bloco4.iloc[:, 0].dropna().unique())}\")\n",
        "print(f\"\\nNota: Bloco 4 tem apenas 1 item, então não é possível calcular Alpha de Cronbach.\")\n",
        "print(\"Alpha de Cronbach requer pelo menos 2 itens.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tratamento de Missing Values\n",
        "\n",
        "Substituir valores faltantes pela média do item.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para tratar missing values (substituir por média do item)\n",
        "def tratar_missing_values(df_bloco):\n",
        "    \"\"\"\n",
        "    Substitui valores faltantes pela média do item.\n",
        "    \"\"\"\n",
        "    df_clean = df_bloco.copy()\n",
        "    \n",
        "    for col in df_clean.columns:\n",
        "        media = df_clean[col].mean()\n",
        "        df_clean[col] = df_clean[col].fillna(media)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Aplicar tratamento de missing values\n",
        "bloco1_clean = tratar_missing_values(bloco1)\n",
        "bloco2_clean = tratar_missing_values(bloco2)\n",
        "bloco3_clean = tratar_missing_values(bloco3)\n",
        "bloco4_clean = tratar_missing_values(bloco4)\n",
        "\n",
        "print(\"Missing values tratados:\")\n",
        "print(f\"Bloco 1 - Antes: {bloco1.isna().sum().sum()}, Depois: {bloco1_clean.isna().sum().sum()}\")\n",
        "print(f\"Bloco 2 - Antes: {bloco2.isna().sum().sum()}, Depois: {bloco2_clean.isna().sum().sum()}\")\n",
        "print(f\"Bloco 3 - Antes: {bloco3.isna().sum().sum()}, Depois: {bloco3_clean.isna().sum().sum()}\")\n",
        "print(f\"Bloco 4 - Antes: {bloco4.isna().sum().sum()}, Depois: {bloco4_clean.isna().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verificação de Escalas\n",
        "\n",
        "Garantir que todas as respostas estão no mesmo formato numérico e verificar se há inversão de escala.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar escalas e valores\n",
        "print(\"=\"*60)\n",
        "print(\"VERIFICAÇÃO DE ESCALAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nBloco 1 - Conhecimento Antes:\")\n",
        "print(f\"  Escala esperada: 0-3\")\n",
        "print(f\"  Valores encontrados: {sorted(bloco1_clean.values.flatten())}\")\n",
        "print(f\"  Min: {bloco1_clean.min().min()}, Max: {bloco1_clean.max().max()}\")\n",
        "\n",
        "print(\"\\nBloco 2 - Conhecimento Depois:\")\n",
        "print(f\"  Escala esperada: 0-3\")\n",
        "print(f\"  Valores encontrados: {sorted(bloco2_clean.values.flatten())}\")\n",
        "print(f\"  Min: {bloco2_clean.min().min()}, Max: {bloco2_clean.max().max()}\")\n",
        "\n",
        "print(\"\\nBloco 3 - Motivação:\")\n",
        "print(f\"  Escala esperada: 1-4\")\n",
        "print(f\"  Valores encontrados: {sorted(bloco3_clean.values.flatten())}\")\n",
        "print(f\"  Min: {bloco3_clean.min().min()}, Max: {bloco3_clean.max().max()}\")\n",
        "\n",
        "print(\"\\nBloco 4 - Percepção de Contribuição:\")\n",
        "print(f\"  Escala esperada: 1-5\")\n",
        "print(f\"  Valores encontrados: {sorted(bloco4_clean.values.flatten())}\")\n",
        "print(f\"  Min: {bloco4_clean.min().min()}, Max: {bloco4_clean.max().max()}\")\n",
        "\n",
        "# Verificar se há necessidade de inverter escala (correlações negativas indicam inversão)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VERIFICAÇÃO DE INVERSÃO DE ESCALA\")\n",
        "print(\"=\"*60)\n",
        "print(\"(Correlações negativas podem indicar necessidade de inversão)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cálculo do Alpha de Cronbach\n",
        "\n",
        "Calcular o Alpha de Cronbach para cada bloco.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular Alpha de Cronbach para cada bloco\n",
        "resultados = {}\n",
        "\n",
        "# Bloco 1\n",
        "alpha1 = cronbach_alpha(bloco1_clean)\n",
        "resultados['Bloco 1 - Conhecimento Antes'] = {\n",
        "    'alpha': alpha1,\n",
        "    'n_items': bloco1_clean.shape[1],\n",
        "    'n_respondentes': bloco1_clean.shape[0]\n",
        "}\n",
        "\n",
        "# Bloco 2\n",
        "alpha2 = cronbach_alpha(bloco2_clean)\n",
        "resultados['Bloco 2 - Conhecimento Depois'] = {\n",
        "    'alpha': alpha2,\n",
        "    'n_items': bloco2_clean.shape[1],\n",
        "    'n_respondentes': bloco2_clean.shape[0]\n",
        "}\n",
        "\n",
        "# Bloco 3\n",
        "alpha3 = cronbach_alpha(bloco3_clean)\n",
        "resultados['Bloco 3 - Motivação'] = {\n",
        "    'alpha': alpha3,\n",
        "    'n_items': bloco3_clean.shape[1],\n",
        "    'n_respondentes': bloco3_clean.shape[0]\n",
        "}\n",
        "\n",
        "# Bloco 4 (não pode calcular alpha com 1 item)\n",
        "resultados['Bloco 4 - Percepção de Contribuição'] = {\n",
        "    'alpha': np.nan,\n",
        "    'n_items': 1,\n",
        "    'n_respondentes': bloco4_clean.shape[0],\n",
        "    'observacao': 'Alpha requer pelo menos 2 itens'\n",
        "}\n",
        "\n",
        "# Criar tabela de resultados\n",
        "tabela_resultados = pd.DataFrame(resultados).T\n",
        "tabela_resultados['alpha'] = tabela_resultados['alpha'].round(3)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"RESULTADOS DO ALPHA DE CRONBACH\")\n",
        "print(\"=\"*70)\n",
        "print(tabela_resultados.to_string())\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETAÇÃO DO ALPHA DE CRONBACH:\")\n",
        "print(\"=\"*70)\n",
        "print(\"α ≥ 0.90: Excelente confiabilidade\")\n",
        "print(\"0.80 ≤ α < 0.90: Boa confiabilidade\")\n",
        "print(\"0.70 ≤ α < 0.80: Aceitável confiabilidade\")\n",
        "print(\"0.60 ≤ α < 0.70: Questionável confiabilidade\")\n",
        "print(\"α < 0.60: Confiabilidade inadequada\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Análise Detalhada por Bloco\n",
        "\n",
        "Para cada bloco, calcular:\n",
        "- Correlações item-total\n",
        "- Alpha se item deletado\n",
        "- Estatísticas descritivas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para análise detalhada de um bloco\n",
        "def analise_detalhada_bloco(df_bloco, nome_bloco):\n",
        "    \"\"\"\n",
        "    Realiza análise detalhada de confiabilidade de um bloco.\n",
        "    \"\"\"\n",
        "    if df_bloco.shape[1] < 2:\n",
        "        print(f\"\\n{nome_bloco}: Não é possível calcular (menos de 2 itens)\")\n",
        "        return None\n",
        "    \n",
        "    # Calcular métricas\n",
        "    alpha_total = cronbach_alpha(df_bloco)\n",
        "    corr_item_total = item_total_correlation(df_bloco)\n",
        "    alphas_se_deletado = alpha_if_deleted(df_bloco)\n",
        "    \n",
        "    # Estatísticas descritivas\n",
        "    descritivas = df_bloco.describe().T[['mean', 'std', 'min', 'max']]\n",
        "    \n",
        "    # Criar DataFrame com resultados\n",
        "    resultado = pd.DataFrame({\n",
        "        'Média': descritivas['mean'],\n",
        "        'Desvio Padrão': descritivas['std'],\n",
        "        'Mínimo': descritivas['min'],\n",
        "        'Máximo': descritivas['max'],\n",
        "        'Correlação Item-Total': corr_item_total,\n",
        "        'Alpha se Item Deletado': alphas_se_deletado\n",
        "    })\n",
        "    \n",
        "    resultado = resultado.round(3)\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"{nome_bloco}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Alpha de Cronbach Total: {alpha_total:.3f}\")\n",
        "    print(f\"\\nAnálise por Item:\")\n",
        "    print(resultado.to_string())\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "# Análise detalhada de cada bloco\n",
        "analise_bloco1 = analise_detalhada_bloco(bloco1_clean, \"BLOCO 1 - CONHECIMENTO ANTES\")\n",
        "analise_bloco2 = analise_detalhada_bloco(bloco2_clean, \"BLOCO 2 - CONHECIMENTO DEPOIS\")\n",
        "analise_bloco3 = analise_detalhada_bloco(bloco3_clean, \"BLOCO 3 - MOTIVAÇÃO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizações - Gráficos de Confiabilidade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfico 1: Alpha de Cronbach por Bloco (Melhorado para artigo)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# Gráfico 1.1: Alpha de Cronbach\n",
        "ax1 = axes[0, 0]\n",
        "blocos = ['Bloco 1\\n(Conhecimento\\nAntes)', \n",
        "          'Bloco 2\\n(Conhecimento\\nDepois)', \n",
        "          'Bloco 3\\n(Motivação)']\n",
        "alphas = [alpha1, alpha2, alpha3]\n",
        "# Cores baseadas na qualidade do alpha\n",
        "colors_alpha = [colors_academic['accent3'] if a >= 0.80 \n",
        "                else colors_academic['accent4'] if a >= 0.70 \n",
        "                else colors_academic['accent2'] for a in alphas]\n",
        "\n",
        "bars = ax1.bar(blocos, alphas, color=colors_alpha, alpha=0.85, \n",
        "               edgecolor=colors_academic['dark'], linewidth=1.5, width=0.6)\n",
        "ax1.axhline(y=0.70, color=colors_academic['accent4'], linestyle='--', \n",
        "            linewidth=1.5, label='Aceitável (α ≥ 0.70)', alpha=0.7)\n",
        "ax1.axhline(y=0.80, color=colors_academic['accent3'], linestyle='--', \n",
        "            linewidth=1.5, label='Bom (α ≥ 0.80)', alpha=0.7)\n",
        "ax1.set_ylabel('Alpha de Cronbach (α)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('(a) Alpha de Cronbach por Bloco', fontsize=13, fontweight='bold', pad=15)\n",
        "ax1.set_ylim(0, 1.05)\n",
        "ax1.legend(loc='upper right', frameon=True, fancybox=True, shadow=False, \n",
        "          framealpha=0.9, edgecolor='gray')\n",
        "ax1.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "ax1.spines['top'].set_visible(False)\n",
        "ax1.spines['right'].set_visible(False)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, alpha in zip(bars, alphas):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.03,\n",
        "             f'{alpha:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "# Gráfico 1.2: Correlações Item-Total (Bloco 1)\n",
        "ax2 = axes[0, 1]\n",
        "if analise_bloco1 is not None:\n",
        "    corr_bloco1 = analise_bloco1['Correlação Item-Total'].sort_values()\n",
        "    y_pos = range(len(corr_bloco1))\n",
        "    bars2 = ax2.barh(y_pos, corr_bloco1.values, color=colors_academic['accent1'], \n",
        "                     alpha=0.85, edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax2.set_yticks(y_pos)\n",
        "    # Encurtar labels para melhor visualização\n",
        "    labels_short = [label.replace(' (antes)', '') for label in corr_bloco1.index]\n",
        "    ax2.set_yticklabels(labels_short, fontsize=9.5)\n",
        "    ax2.set_xlabel('Correlação Item-Total', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('(b) Bloco 1: Correlações Item-Total', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax2.axvline(x=0.30, color=colors_academic['accent2'], linestyle='--', \n",
        "                linewidth=1.5, label='Mínimo aceitável (0.30)', alpha=0.7)\n",
        "    ax2.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax2.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax2.set_xlim(0, max(corr_bloco1.values) * 1.15)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "    ax2.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(corr_bloco1.items()):\n",
        "        ax2.text(val + 0.02, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "# Gráfico 1.3: Correlações Item-Total (Bloco 2)\n",
        "ax3 = axes[1, 0]\n",
        "if analise_bloco2 is not None:\n",
        "    corr_bloco2 = analise_bloco2['Correlação Item-Total'].sort_values()\n",
        "    y_pos = range(len(corr_bloco2))\n",
        "    bars3 = ax3.barh(y_pos, corr_bloco2.values, color=colors_academic['accent4'], \n",
        "                     alpha=0.85, edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax3.set_yticks(y_pos)\n",
        "    labels_short = [label.replace(' (depois)', '') for label in corr_bloco2.index]\n",
        "    ax3.set_yticklabels(labels_short, fontsize=9.5)\n",
        "    ax3.set_xlabel('Correlação Item-Total', fontsize=12, fontweight='bold')\n",
        "    ax3.set_title('(c) Bloco 2: Correlações Item-Total', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax3.axvline(x=0.30, color=colors_academic['accent2'], linestyle='--', \n",
        "                linewidth=1.5, label='Mínimo aceitável (0.30)', alpha=0.7)\n",
        "    ax3.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax3.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax3.set_xlim(0, max(corr_bloco2.values) * 1.15)\n",
        "    ax3.spines['top'].set_visible(False)\n",
        "    ax3.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(corr_bloco2.items()):\n",
        "        ax3.text(val + 0.02, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "# Gráfico 1.4: Correlações Item-Total (Bloco 3)\n",
        "ax4 = axes[1, 1]\n",
        "if analise_bloco3 is not None:\n",
        "    corr_bloco3 = analise_bloco3['Correlação Item-Total'].sort_values()\n",
        "    y_pos = range(len(corr_bloco3))\n",
        "    bars4 = ax4.barh(y_pos, corr_bloco3.values, color=colors_academic['secondary'], \n",
        "                     alpha=0.85, edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax4.set_yticks(y_pos)\n",
        "    ax4.set_yticklabels(corr_bloco3.index, fontsize=9.5)\n",
        "    ax4.set_xlabel('Correlação Item-Total', fontsize=12, fontweight='bold')\n",
        "    ax4.set_title('(d) Bloco 3: Correlações Item-Total', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax4.axvline(x=0.30, color=colors_academic['accent2'], linestyle='--', \n",
        "                linewidth=1.5, label='Mínimo aceitável (0.30)', alpha=0.7)\n",
        "    ax4.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax4.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax4.set_xlim(0, max(corr_bloco3.values) * 1.15)\n",
        "    ax4.spines['top'].set_visible(False)\n",
        "    ax4.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(corr_bloco3.items()):\n",
        "        ax4.text(val + 0.02, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Análise de Confiabilidade - Alpha de Cronbach', \n",
        "             fontsize=15, fontweight='bold', y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.savefig('../img/cronbach_alpha_analysis.png', dpi=300, bbox_inches='tight', \n",
        "            facecolor='white', edgecolor='none')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfico 2: Alpha se Item Deletado (Melhorado para artigo)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# Bloco 1\n",
        "ax1 = axes[0]\n",
        "if analise_bloco1 is not None:\n",
        "    alpha_del_bloco1 = analise_bloco1['Alpha se Item Deletado'].sort_values()\n",
        "    alpha_total_bloco1 = alpha1\n",
        "    \n",
        "    y_pos = range(len(alpha_del_bloco1))\n",
        "    bars1 = ax1.barh(y_pos, alpha_del_bloco1.values, \n",
        "                     color=colors_academic['accent1'], alpha=0.85, \n",
        "                     edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax1.axvline(x=alpha_total_bloco1, color=colors_academic['accent2'], \n",
        "                linestyle='--', linewidth=2, \n",
        "                label=f'Alpha Total (α = {alpha_total_bloco1:.3f})', alpha=0.8)\n",
        "    ax1.set_yticks(y_pos)\n",
        "    labels_short = [label.replace(' (antes)', '') for label in alpha_del_bloco1.index]\n",
        "    ax1.set_yticklabels(labels_short, fontsize=9.5)\n",
        "    ax1.set_xlabel('Alpha de Cronbach (α)', fontsize=12, fontweight='bold')\n",
        "    ax1.set_title('(a) Bloco 1: Alpha se Item Deletado', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax1.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax1.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax1.set_xlim(0.75, 1.0)\n",
        "    ax1.spines['top'].set_visible(False)\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(alpha_del_bloco1.items()):\n",
        "        ax1.text(val + 0.002, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "# Bloco 2\n",
        "ax2 = axes[1]\n",
        "if analise_bloco2 is not None:\n",
        "    alpha_del_bloco2 = analise_bloco2['Alpha se Item Deletado'].sort_values()\n",
        "    alpha_total_bloco2 = alpha2\n",
        "    \n",
        "    y_pos = range(len(alpha_del_bloco2))\n",
        "    bars2 = ax2.barh(y_pos, alpha_del_bloco2.values, \n",
        "                     color=colors_academic['accent4'], alpha=0.85, \n",
        "                     edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax2.axvline(x=alpha_total_bloco2, color=colors_academic['accent2'], \n",
        "                linestyle='--', linewidth=2, \n",
        "                label=f'Alpha Total (α = {alpha_total_bloco2:.3f})', alpha=0.8)\n",
        "    ax2.set_yticks(y_pos)\n",
        "    labels_short = [label.replace(' (depois)', '') for label in alpha_del_bloco2.index]\n",
        "    ax2.set_yticklabels(labels_short, fontsize=9.5)\n",
        "    ax2.set_xlabel('Alpha de Cronbach (α)', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('(b) Bloco 2: Alpha se Item Deletado', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax2.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax2.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax2.set_xlim(0.70, 0.95)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "    ax2.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(alpha_del_bloco2.items()):\n",
        "        ax2.text(val + 0.002, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "# Bloco 3\n",
        "ax3 = axes[2]\n",
        "if analise_bloco3 is not None:\n",
        "    alpha_del_bloco3 = analise_bloco3['Alpha se Item Deletado'].sort_values()\n",
        "    alpha_total_bloco3 = alpha3\n",
        "    \n",
        "    y_pos = range(len(alpha_del_bloco3))\n",
        "    bars3 = ax3.barh(y_pos, alpha_del_bloco3.values, \n",
        "                     color=colors_academic['secondary'], alpha=0.85, \n",
        "                     edgecolor=colors_academic['dark'], linewidth=1.2, height=0.7)\n",
        "    ax3.axvline(x=alpha_total_bloco3, color=colors_academic['accent2'], \n",
        "                linestyle='--', linewidth=2, \n",
        "                label=f'Alpha Total (α = {alpha_total_bloco3:.3f})', alpha=0.8)\n",
        "    ax3.set_yticks(y_pos)\n",
        "    ax3.set_yticklabels(alpha_del_bloco3.index, fontsize=9.5)\n",
        "    ax3.set_xlabel('Alpha de Cronbach (α)', fontsize=12, fontweight='bold')\n",
        "    ax3.set_title('(c) Bloco 3: Alpha se Item Deletado', fontsize=13, fontweight='bold', pad=15)\n",
        "    ax3.legend(loc='lower right', frameon=True, fancybox=True, shadow=False, \n",
        "              framealpha=0.9, edgecolor='gray')\n",
        "    ax3.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.8)\n",
        "    ax3.set_xlim(0.50, 0.75)\n",
        "    ax3.spines['top'].set_visible(False)\n",
        "    ax3.spines['right'].set_visible(False)\n",
        "    \n",
        "    # Adicionar valores\n",
        "    for i, (idx, val) in enumerate(alpha_del_bloco3.items()):\n",
        "        ax3.text(val + 0.002, i, f'{val:.3f}', va='center', fontsize=9.5, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Análise: Alpha de Cronbach se Item Deletado', \n",
        "             fontsize=15, fontweight='bold', y=1.02)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.savefig('../img/cronbach_alpha_if_deleted.png', dpi=300, bbox_inches='tight', \n",
        "            facecolor='white', edgecolor='none')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETAÇÃO: Alpha se Item Deletado\")\n",
        "print(\"=\"*70)\n",
        "print(\"Se o alpha aumenta ao deletar um item, esse item pode estar reduzindo\")\n",
        "print(\"a consistência interna e pode ser considerado para remoção.\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tabelas de Confiabilidade\n",
        "\n",
        "Gerar tabelas formatadas com os resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar tabela resumo final\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TABELA RESUMO - ALPHA DE CRONBACH\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "tabela_resumo = pd.DataFrame({\n",
        "    'Bloco': ['Bloco 1 - Conhecimento Antes', \n",
        "              'Bloco 2 - Conhecimento Depois', \n",
        "              'Bloco 3 - Motivação'],\n",
        "    'N Items': [bloco1_clean.shape[1], bloco2_clean.shape[1], bloco3_clean.shape[1]],\n",
        "    'N Respondentes': [bloco1_clean.shape[0], bloco2_clean.shape[0], bloco3_clean.shape[0]],\n",
        "    'Alpha de Cronbach': [alpha1, alpha2, alpha3],\n",
        "    'Interpretação': [\n",
        "        'Excelente' if alpha1 >= 0.90 else 'Boa' if alpha1 >= 0.80 else 'Aceitável' if alpha1 >= 0.70 else 'Questionável' if alpha1 >= 0.60 else 'Inadequada',\n",
        "        'Excelente' if alpha2 >= 0.90 else 'Boa' if alpha2 >= 0.80 else 'Aceitável' if alpha2 >= 0.70 else 'Questionável' if alpha2 >= 0.60 else 'Inadequada',\n",
        "        'Excelente' if alpha3 >= 0.90 else 'Boa' if alpha3 >= 0.80 else 'Aceitável' if alpha3 >= 0.70 else 'Questionável' if alpha3 >= 0.60 else 'Inadequada'\n",
        "    ]\n",
        "})\n",
        "\n",
        "tabela_resumo['Alpha de Cronbach'] = tabela_resumo['Alpha de Cronbach'].round(3)\n",
        "print(tabela_resumo.to_string(index=False))\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabelas detalhadas por bloco\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TABELAS DETALHADAS POR BLOCO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for nome_bloco, df_analise in [(\"BLOCO 1 - CONHECIMENTO ANTES\", analise_bloco1),\n",
        "                                (\"BLOCO 2 - CONHECIMENTO DEPOIS\", analise_bloco2),\n",
        "                                (\"BLOCO 3 - MOTIVAÇÃO\", analise_bloco3)]:\n",
        "    if df_analise is not None:\n",
        "        print(f\"\\n{nome_bloco}\")\n",
        "        print(\"-\"*80)\n",
        "        print(df_analise.to_string())\n",
        "        print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretação e Recomendações\n",
        "\n",
        "### Interpretação dos Resultados:\n",
        "\n",
        "1. **Alpha de Cronbach (α)**: Mede a consistência interna dos itens\n",
        "   - Valores próximos a 1 indicam alta consistência\n",
        "   - Valores abaixo de 0.70 podem indicar problemas de confiabilidade\n",
        "\n",
        "2. **Correlação Item-Total**: \n",
        "   - Valores acima de 0.30 são geralmente aceitáveis\n",
        "   - Valores muito baixos podem indicar que o item não mede o mesmo constructo\n",
        "\n",
        "3. **Alpha se Item Deletado**:\n",
        "   - Se aumenta ao deletar um item, esse item pode estar reduzindo a consistência\n",
        "   - Se diminui, o item está contribuindo positivamente para a confiabilidade\n",
        "\n",
        "### Recomendações:\n",
        "\n",
        "- **Itens com correlação item-total < 0.30**: Considerar revisão ou remoção\n",
        "- **Itens que aumentam o alpha quando deletados**: Avaliar necessidade de remoção\n",
        "- **Alpha < 0.70**: Revisar itens ou considerar reformulação do instrumento\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
